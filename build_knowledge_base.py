from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.document_loaders import DirectoryLoader, JSONLoader
import os
from pathlib import Path
from typing import Dict, Any

# é…ç½®å‚æ•°
LOCAL_MODEL_PATH = "./local_models/bge-small-zh-v1.5"
CHROMA_DB_PATH = "./chroma_db"
DATA_DIR = "processed"


def metadata_func(record: Dict[str, Any], metadata: Dict[str, Any]) -> Dict[str, Any]:
    """ä»JSONè®°å½•ä¸­æå–å…ƒæ•°æ®"""
    metadata.update({
        "episode": record.get("episode_number", 0),
        "title": record.get("episode_title", ""),
        "scene_number": record.get("scene_number", ""),
        "location": record.get("location", ""),
        "characters": ", ".join(record.get("characters", []))
    })
    return metadata


def load_documents(data_dir: str = DATA_DIR):
    """åŠ è½½å¤„ç†åçš„å‰§æœ¬æ•°æ®"""
    loader = DirectoryLoader(
        path=data_dir,
        glob="*.json",
        loader_cls=JSONLoader,
        loader_kwargs={
            "jq_schema": ".scenes[]",  # ç›´æ¥ä»scenesæ•°ç»„æå–
            "content_key": "content",  # å¯¹åº”æ–°æ ¼å¼ä¸­çš„contentå­—æ®µ
            "metadata_func": metadata_func,
            "text_content": True  # ç¡®ä¿è¿”å›åŸå§‹æ–‡æœ¬
        },
        show_progress=True
    )
    return loader.load()


def build_knowledge_base():
    # åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨ï¼ˆä¿æŒåŸæœ‰å‚æ•°ï¼‰
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=300,
        chunk_overlap=50,
        length_function=len,
        add_start_index=True
    )

    # åŠ è½½å¹¶åˆ†å‰²æ–‡æ¡£
    print("â³ æ­£åœ¨åŠ è½½æ–‡æ¡£...")
    documents = load_documents()
    print(f"ğŸ“„ åŸå§‹æ–‡æ¡£æ•°: {len(documents)}")

    splits = text_splitter.split_documents(documents)
    print(f"âœ‚ï¸ åˆ†å‰²åæ–‡æ¡£å—æ•°: {len(splits)}")

    # åˆå§‹åŒ–æœ¬åœ°åµŒå…¥æ¨¡å‹ï¼ˆä¿æŒä¸å˜ï¼‰
    print("ğŸ”§ æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹...")
    embedding = HuggingFaceEmbeddings(
        model_name=LOCAL_MODEL_PATH,
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True}
    )

    # åˆ›å»ºå‘é‡æ•°æ®åº“ï¼ˆä¿æŒä¸å˜ï¼‰
    print("ğŸ—ï¸ æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“...")
    vectordb = Chroma.from_documents(
        documents=splits,
        embedding=embedding,
        persist_directory=CHROMA_DB_PATH,
        collection_name="zhenhuan_zhuan",
        collection_metadata={"hnsw:space": "cosine"}
    )

    # ä¿å­˜æ•°æ®åº“ï¼ˆä¿æŒä¸å˜ï¼‰
    vectordb.persist()
    print(f"âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼ä¿å­˜è·¯å¾„: {os.path.abspath(CHROMA_DB_PATH)}")


if __name__ == "__main__":
    build_knowledge_base()